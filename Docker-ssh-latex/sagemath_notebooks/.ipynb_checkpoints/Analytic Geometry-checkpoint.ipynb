{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a853207",
   "metadata": {},
   "outputs": [],
   "source": [
    "%display latex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be812cbd",
   "metadata": {},
   "source": [
    "### Analytic Geometry"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f2a4a20",
   "metadata": {},
   "source": [
    "$ \\textbf{1. What are the Geometric Vectors ? } $\n",
    "\n",
    "Geometric vectors are mathematical entities that have both magnitude and direction. They are often represented as arrows in a coordinate system, where the length of the arrow represents the magnitude of the vector, and the direction of the arrow indicates its orientation.\n",
    "\n",
    "Vectors can be used to represent various physical quantities such as displacement, velocity, force, and more. They play a crucial role in geometry, physics, and other mathematical disciplines.\n",
    "\n",
    "There are two main types of vectors: position vectors and free vectors. A position vector describes the position of a point in space relative to a reference point, while a free vector represents a quantity that has both magnitude and direction but is independent of any specific point in space.\n",
    "\n",
    "Understanding vectors involves operations like addition, subtraction, scalar multiplication, and the inner product (dot product), which is a way to combine two vectors to obtain a scalar quantity. The dot product of two vectors, $ \\mathbf{A} $ and $ \\mathbf{B} $, is given by:\n",
    "\n",
    "$ \\mathbf{A} \\cdot \\mathbf{B} = |\\mathbf{A}| \\cdot |\\mathbf{B}| \\cdot \\cos(\\theta) $\n",
    "\n",
    "where $ |\\mathbf{A}| $ and $ |\\mathbf{B}| $ are the magnitudes of the vectors, and $ \\theta $ is the angle between them.\n",
    "\n",
    "This operation is useful in various applications, including calculating work done, finding angles between vectors, and determining projections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3cfe45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8bc71e18",
   "metadata": {},
   "source": [
    "$ \\textbf{2. What is Inner Dot Product of geometric vectors? } $\n",
    "\n",
    "The inner product of geometric vectors is also known as the dot product. It's a mathematical operation that takes two vectors and produces a scalar. For two vectors $ \\mathbf{A} = (A_1, A_2, A_3) $ and $ \\mathbf{B} = (B_1, B_2, B_3) $, the dot product $ \\mathbf{A} \\cdot \\mathbf{B} $ is calculated as follows:\n",
    "\n",
    "$ \\mathbf{A} \\cdot \\mathbf{B} = A_1 \\cdot B_1 + A_2 \\cdot B_2 + A_3 \\cdot B_3 $\n",
    "\n",
    "Alternatively, in terms of magnitudes and the angle $ \\theta $ between the vectors:\n",
    "\n",
    "$ \\mathbf{A} \\cdot \\mathbf{B} = |\\mathbf{A}| \\cdot |\\mathbf{B}| \\cdot \\cos(\\theta) $\n",
    "\n",
    "The dot product is a versatile operation with various applications. It can be used to find the angle between vectors, calculate work done, determine projections, and more. If the dot product of two vectors is zero, it means the vectors are orthogonal (perpendicular). If the dot product is positive, the angle between them is acute, and if it's negative, the angle is obtuse."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0955917c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cc228a80",
   "metadata": {},
   "source": [
    "$ \\textbf{3. What is the length of geometric vectors? } $\n",
    "\n",
    "The length of a geometric vector is also known as its magnitude or norm. For a vector $ \\mathbf{V} $ in three-dimensional space with components $ (V_1, V_2, V_3) $, the magnitude $ |\\mathbf{V}| $ is calculated using the Pythagorean theorem:\n",
    "\n",
    "$ |\\mathbf{V}| = \\sqrt{V_1^2 + V_2^2 + V_3^2} $\n",
    "\n",
    "In general terms, for a vector $ \\mathbf{V} $ in n-dimensional space with components $ (V_1, V_2, \\ldots, V_n) $, the magnitude is given by:\n",
    "\n",
    "$ |\\mathbf{V}| = \\sqrt{V_1^2 + V_2^2 + \\ldots + V_n^2} $\n",
    "\n",
    "The magnitude of a vector represents its length or size. It is always a non-negative value. Geometrically, the magnitude can be thought of as the distance from the origin to the point represented by the vector in a coordinate system.\n",
    "\n",
    "The magnitude is a fundamental concept in vector algebra and is used in various applications, including physics, engineering, and computer science."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb2c340",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b6de277f",
   "metadata": {},
   "source": [
    "$ \\textbf{ 4. What is Symmetric Matrices ? }$\n",
    "\n",
    "Sure thing! Here's your text with inline and display math mode using `$`:\n",
    "\n",
    "A symmetric matrix is a square matrix that is equal to its transpose. In mathematical terms, let $ A $ be a square matrix of order $ n $ (an $ n \\times n $ matrix). $ A $ is symmetric if it satisfies the condition:\n",
    "\n",
    "$ A = A^T $\n",
    "\n",
    "Here, $ A^T $ denotes the transpose of matrix $ A $.\n",
    "\n",
    "In LaTeX syntax:\n",
    "\n",
    "$ A = A^T $\n",
    "\n",
    "This means that the elements of the matrix are symmetric with respect to the main diagonal. If $ A $ has elements $ a_{ij} $, where $ i $ is the row index and $ j $ is the column index, then for a symmetric matrix:\n",
    "\n",
    "$ a_{ij} = a_{ji} $\n",
    "\n",
    "for all $ i $ and $ j $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27b8527",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "88e1442d",
   "metadata": {},
   "source": [
    "$ \\textbf{5. What is Symmetric Positive Definite Matrices ?  }$\n",
    "\n",
    "\n",
    "A symmetric positive definite matrix is a special kind of symmetric matrix that possesses certain positive-definite properties. Let's break down the terms:\n",
    "\n",
    "1. **Symmetric Matrix**: As mentioned earlier, a matrix $A$ is symmetric if it is equal to its transpose, i.e., $A = A^T$.\n",
    "\n",
    "2. **Positive Definite Matrix**: A symmetric matrix $A$ is positive definite if, for any non-zero column vector $x$, the quadratic form $x^T A x$ is always positive, except when $x$ is the zero vector.\n",
    "\n",
    "In mathematical terms, a symmetric matrix $A$ is positive definite if, for all non-zero vectors $x$ in $\\mathbb{R}^n$, the following inequality holds:\n",
    "\n",
    "$\\ x^T A x > 0 \\$\n",
    "\n",
    "Additionally, the eigenvalues of a positive definite matrix are all positive.\n",
    "\n",
    "In LaTeX syntax:\n",
    "\n",
    "$\\ x^T A x > 0 \\$\n",
    "\n",
    "Positive definite matrices have important applications in various fields, including optimization, numerical analysis, and statistics. They play a crucial role in algorithms and mathematical formulations where the positivity and definiteness of a matrix are essential properties."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d77b6c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "eaefa92f",
   "metadata": {},
   "source": [
    "$ \\textbf{6. What is Quadratic Forms on a R^n? ?  }$\n",
    "\n",
    "A quadratic form on $\\mathbb{R}^n$ is a mathematical expression of the form:\n",
    "\n",
    "\\[ Q(\\mathbf{x}) = \\mathbf{x}^T A \\mathbf{x} \\]\n",
    "\n",
    "where:\n",
    "- $\\mathbf{x}$ is a column vector in $\\mathbb{R}^n$.\n",
    "- $A$ is a symmetric matrix in $\\mathbb{R}^{n \\times n}$.\n",
    "\n",
    "The expression $\\mathbf{x}^T A \\mathbf{x}$ represents a quadratic form because it involves the square (quadratic) terms of the components of $\\mathbf{x}$. The symmetric matrix $A$ defines the coefficients of these quadratic terms.\n",
    "\n",
    "Quadratic forms have applications in various areas, including optimization, physics, statistics, and engineering. They often arise in problems where the relationship between variables is quadratic. The properties of the quadratic form, such as whether it is positive definite, negative definite, or indefinite, provide valuable information about the behavior of the associated system or function.\n",
    "\n",
    "For a symmetric matrix $A$, the quadratic form $\\mathbf{x}^T A \\mathbf{x}$ is:\n",
    "\n",
    "- Positive definite if $\\mathbf{x}^T A \\mathbf{x} > 0$ for all non-zero $\\mathbf{x}$.\n",
    "- Negative definite if $\\mathbf{x}^T A \\mathbf{x} < 0$ for all non-zero $\\mathbf{x}$.\n",
    "- Indefinite if it can take both positive and negative values depending on the choice of $\\mathbf{x}$.\n",
    "\n",
    "Understanding the properties of quadratic forms is crucial in various mathematical and scientific applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517d9938",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "043171e8",
   "metadata": {},
   "source": [
    "$ \\textbf{7. Length and Distances of Geometric Vectors  }$\n",
    "\n",
    "In the context of geometric vectors, the length of a vector is also referred to as its magnitude or norm. The length of a vector $ \\mathbf{V} $ in $ \\mathbb{R}^n $ is denoted by $ |\\mathbf{V}| $ and is calculated using the Pythagorean theorem:\n",
    "\n",
    "$ |\\mathbf{V}| = \\sqrt{V_1^2 + V_2^2 + \\ldots + V_n^2} $\n",
    "\n",
    "Here, $ V_1, V_2, \\ldots, V_n $ are the components of the vector $ \\mathbf{V} $.\n",
    "\n",
    "The length of a vector represents its size or distance from the origin in an $ n $-dimensional space. Geometrically, if you represent a vector as an arrow in space, the length of the arrow corresponds to the magnitude of the vector.\n",
    "\n",
    "Distance between two vectors $ \\mathbf{A} $ and $ \\mathbf{B} $ in $ \\mathbb{R}^n $ is often expressed as the magnitude of the vector difference $ \\mathbf{A} - \\mathbf{B} $:\n",
    "\n",
    "$ |\\mathbf{A} - \\mathbf{B}| = \\sqrt{(A_1 - B_1)^2 + (A_2 - B_2)^2 + \\ldots + (A_n - B_n)^2} $\n",
    "\n",
    "This distance represents the length of the straight line connecting the two points represented by $ \\mathbf{A} $ and $ \\mathbf{B} $ in the vector space.\n",
    "\n",
    "In both cases, the Pythagorean theorem is the key to calculating lengths and distances in vector spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84d7272",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c5139931",
   "metadata": {},
   "source": [
    "$ \\textbf{8. Angle between Geometric Vectors }$\n",
    "\n",
    "\n",
    "The angle $ \\theta $ between two geometric vectors $ \\mathbf{A} $ and $ \\mathbf{B} $ in $ \\mathbb{R}^n $ can be found using the dot product and the magnitudes of the vectors. The formula for the angle $ \\theta $ is given by:\n",
    "\n",
    "$ \\cos(\\theta) = \\frac{\\mathbf{A} \\cdot \\mathbf{B}}{|\\mathbf{A}| \\cdot |\\mathbf{B}|} $\n",
    "\n",
    "Here:\n",
    "- $ \\mathbf{A} \\cdot \\mathbf{B} $ is the dot product of vectors $ \\mathbf{A} $ and $ \\mathbf{B} $.\n",
    "- $ |\\mathbf{A}| $ and $ |\\mathbf{B}| $ are the magnitudes (lengths) of vectors $ \\mathbf{A} $ and $ \\mathbf{B} $ respectively.\n",
    "\n",
    "You can solve for $ \\theta $ using the arccosine function:\n",
    "\n",
    "$ \\theta = \\arccos\\left(\\frac{\\mathbf{A} \\cdot \\mathbf{B}}{|\\mathbf{A}| \\cdot |\\mathbf{B}|}\\right) $\n",
    "\n",
    "This formula works for vectors in any dimension, not just the traditional three-dimensional space.\n",
    "\n",
    "The dot product $ \\mathbf{A} \\cdot \\mathbf{B} $ represents the product of the magnitudes of the vectors and the cosine of the angle between them. The division by the product of magnitudes normalizes this to give the cosine of the angle directly.\n",
    "\n",
    "This formula is useful for finding angles between vectors in applications such as physics, computer graphics, and engineering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a02e91",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "03ae82fc",
   "metadata": {},
   "source": [
    "$ \\textbf{9. Orthogonality between Geometric Vectors. Give me an example  }$\n",
    "\n",
    "\n",
    "Vectors are orthogonal (perpendicular) if their dot product is zero. Mathematically, for two vectors $ \\mathbf{A} $ and $ \\mathbf{B} $ in $ \\mathbb{R}^n $, they are orthogonal if:\n",
    "\n",
    "$ \\mathbf{A} \\cdot \\mathbf{B} = 0 $\n",
    "\n",
    "Let's go through a simple example with two vectors in $ \\mathbb{R}^3 $:\n",
    "\n",
    "Consider vector $ \\mathbf{A} = (1, 2, -1) $ and vector $ \\mathbf{B} = (3, -1, 2) $.\n",
    "\n",
    "To check if they are orthogonal, calculate their dot product:\n",
    "\n",
    "$ \\mathbf{A} \\cdot \\mathbf{B} = (1)(3) + (2)(-1) + (-1)(2) $\n",
    "$ = 3 - 2 - 2 $\n",
    "$ = -1 $\n",
    "\n",
    "Since the dot product is not equal to zero, vectors $ \\mathbf{A} $ and $ \\mathbf{B} $ are not orthogonal.\n",
    "\n",
    "Let's take another example:\n",
    "\n",
    "Consider vector $ \\mathbf{C} = (1, -1, 0) $ and vector $ \\mathbf{D} = (2, 2, 1) $.\n",
    "\n",
    "To check if they are orthogonal, calculate their dot product:\n",
    "\n",
    "$ \\mathbf{C} \\cdot \\mathbf{D} = (1)(2) + (-1)(2) + (0)(1) $\n",
    "$ = 2 - 2 + 0 $\n",
    "$ = 0 $\n",
    "\n",
    "Since the dot product is zero, vectors $ \\mathbf{C} $ and $ \\mathbf{D} $ are orthogonal.\n",
    "\n",
    "In this example, $ \\mathbf{C} $ and $ \\mathbf{D} $ are perpendicular, as their dot product is zero. This is a fundamental property of orthogonal vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec00bb5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6761c2f5",
   "metadata": {},
   "source": [
    "$ \\textbf{10. What is General inner product of a symmetric positive definite matrix? With example  }$\n",
    "\n",
    "The general inner product of a symmetric positive definite matrix $A$ with vectors $\\mathbf{u}$ and $\\mathbf{v}$ is defined as:\n",
    "\n",
    "$$\n",
    "\\langle \\mathbf{u}, \\mathbf{v} \\rangle_A = \\mathbf{u}^T A \\mathbf{v}\n",
    "$$\n",
    "\n",
    "Here, $\\mathbf{u}^T$ denotes the transpose of $\\mathbf{u}$. This inner product is weighted by the positive definite matrix $A$.\n",
    "\n",
    "Now, let's go through an example with a specific symmetric positive definite matrix. Consider the following matrix:\n",
    "\n",
    "$$\n",
    "A = \\begin{bmatrix} 2 & -1 \\\\ -1 & 4 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "This matrix is symmetric and positive definite.\n",
    "\n",
    "Now, let $\\mathbf{u} = \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix}$ and $\\mathbf{v} = \\begin{bmatrix} -1 \\\\ 3 \\end{bmatrix}$.\n",
    "\n",
    "The general inner product is:\n",
    "\n",
    "$$\n",
    "\\langle \\mathbf{u}, \\mathbf{v} \\rangle_A = \\mathbf{u}^T A \\mathbf{v} = \\begin{bmatrix} 1 & 2 \\end{bmatrix} \\begin{bmatrix} 2 & -1 \\\\ -1 & 4 \\end{bmatrix} \\begin{bmatrix} -1 \\\\ 3 \\end{bmatrix}\n",
    "$$\n",
    "\n",
    "Performing the matrix multiplications:\n",
    "\n",
    "$$\n",
    "= \\begin{bmatrix} 1 & 2 \\end{bmatrix} \\begin{bmatrix} -4 \\\\ 11 \\end{bmatrix} = -4 + 22 = 18\n",
    "$$\n",
    "\n",
    "So, in this example, the general inner product $\\langle \\mathbf{u}, \\mathbf{v} \\rangle_A$ is 18. The positive definiteness of matrix $A$ ensures that this inner product is positive for non-zero vectors $\\mathbf{u}$ and $\\mathbf{v}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab503c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "150e42b9",
   "metadata": {},
   "source": [
    "$ \\textbf{11. What is length and distance in General inner product of a symmetric positive definite matrix? With example  }$\n",
    "\n",
    "In the context of the general inner product with a symmetric positive definite matrix $A$, the length (or norm) of a vector $\\mathbf{u}$ is defined as:\n",
    "\n",
    "$ \n",
    "\\|\\mathbf{u}\\|_A = \\sqrt{\\langle \\mathbf{u}, \\mathbf{u} \\rangle_A}\n",
    "$ \n",
    "\n",
    "And the distance between two vectors $\\mathbf{u}$ and $\\mathbf{v}$ is defined as:\n",
    "\n",
    "$ \n",
    "\\text{dist}_A(\\mathbf{u}, \\mathbf{v}) = \\|\\mathbf{u} - \\mathbf{v}\\|_A\n",
    "$ \n",
    "\n",
    "Let's go through an example with a symmetric positive definite matrix $A$ to illustrate these concepts. Consider the matrix:\n",
    "\n",
    "$ \n",
    "A = \\begin{bmatrix} 2 & -1 \\\\ -1 & 4 \\end{bmatrix}\n",
    "$ \n",
    "\n",
    "This matrix is symmetric and positive definite.\n",
    "\n",
    "Now, let $\\mathbf{u} = \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix}$ and $\\mathbf{v} = \\begin{bmatrix} -1 \\\\ 3 \\end{bmatrix}$.\n",
    "\n",
    "The length of $\\mathbf{u}$ with respect to $A$ is:\n",
    "\n",
    "$ \n",
    "\\|\\mathbf{u}\\|_A = \\sqrt{\\langle \\mathbf{u}, \\mathbf{u} \\rangle_A}\n",
    "$ \n",
    "\n",
    "$ \n",
    "= \\sqrt{\\mathbf{u}^T A \\mathbf{u}}\n",
    "$ \n",
    "\n",
    "$ \n",
    "= \\sqrt{\\begin{bmatrix} 1 & 2 \\end{bmatrix} \\begin{bmatrix} 2 & -1 \\\\ -1 & 4 \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix}}\n",
    "$ \n",
    "\n",
    "Performing the matrix multiplication:\n",
    "\n",
    "$ \n",
    "= \\sqrt{\\begin{bmatrix} 1 & 2 \\end{bmatrix} \\begin{bmatrix} 3 \\\\ 7 \\end{bmatrix}}\n",
    "$ \n",
    "\n",
    "$ \n",
    "= \\sqrt{17}\n",
    "$ \n",
    "\n",
    "So, the length of $\\mathbf{u}$ with respect to $A$ is $\\sqrt{17}$.\n",
    "\n",
    "Similarly, the distance between $\\mathbf{u}$ and $\\mathbf{v}$ with respect to $A$ is:\n",
    "\n",
    "$ \n",
    "\\text{dist}_A(\\mathbf{u}, \\mathbf{v}) = \\|\\mathbf{u} - \\mathbf{v}\\|_A\n",
    "$ \n",
    "\n",
    "$ \n",
    "= \\sqrt{\\langle \\mathbf{u} - \\mathbf{v}, \\mathbf{u} - \\mathbf{v} \\rangle_A}\n",
    "$ \n",
    "\n",
    "$ \n",
    "= \\sqrt{\\begin{bmatrix} 2 & -1 \\end{bmatrix} \\begin{bmatrix} 3 & -4 \\\\ -4 & 1 \\end{bmatrix} \\begin{bmatrix} 2 \\\\ -1 \\end{bmatrix}}\n",
    "$ \n",
    "\n",
    "Performing the matrix multiplication:\n",
    "\n",
    "$ \n",
    "= \\sqrt{\\begin{bmatrix} 2 & -1 \\end{bmatrix} \\begin{bmatrix} 8 \\\\ -9 \\end{bmatrix}}\n",
    "$ \n",
    "\n",
    "$ \n",
    "= \\sqrt{25}\n",
    "$ \n",
    "\n",
    "So, the distance between $\\mathbf{u}$ and $\\mathbf{v}$ with respect to $A$ is 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ae4503",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "daa1b000",
   "metadata": {},
   "source": [
    "$ \\textbf{12. What is orthogonal Matrix ?  }$\n",
    "\n",
    "An orthogonal matrix is a square matrix where the transpose of the matrix is equal to its inverse. In mathematical terms, for a square matrix $ Q $, it is orthogonal if:\n",
    "\n",
    "$ Q^T \\cdot Q = Q \\cdot Q^T = I $\n",
    "\n",
    "where $ Q^T $ is the transpose of $ Q $, $ I $ is the identity matrix, and $ \\cdot $ represents matrix multiplication.\n",
    "\n",
    "This condition implies that the columns (and rows) of the matrix are orthonormal vectors. Orthonormal vectors are vectors with a magnitude of 1 (unit vectors) that are mutually perpendicular (orthogonal). The orthogonality of the matrix ensures that the transformation represented by the matrix preserves the length of vectors and the angles between them.\n",
    "\n",
    "The inverse of an orthogonal matrix is simply its transpose, and vice versa:\n",
    "\n",
    "$ Q^{-1} = Q^T $\n",
    "\n",
    "Orthogonal matrices have several important properties and applications in linear algebra, geometry, and various mathematical and computational fields. They are commonly used in transformations, such as rotations and reflections, where preserving distances and angles is essential."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "414ff8c3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "615eaf15",
   "metadata": {},
   "source": [
    "$ \\textbf{13. Explain what is Orthogonal, Orthonormal Basis. Give example for each  }$\n",
    "\n",
    "Sure, let's break down the concepts of orthogonal and orthonormal bases.\n",
    "\n",
    "### Orthogonal Basis:\n",
    "\n",
    "An orthogonal basis for a vector space is a set of vectors where each pair of vectors is orthogonal (perpendicular) to each other. Mathematically, let's say you have vectors $ \\mathbf{v}_1, \\mathbf{v}_2, \\ldots, \\mathbf{v}_n $ in a vector space. This set of vectors is an orthogonal basis if:\n",
    "\n",
    "$ \\mathbf{v}_i \\cdot \\mathbf{v}_j = 0 \\quad \\text{for } i \\neq j $\n",
    "\n",
    "In other words, the dot product of any two distinct vectors in the set is zero.\n",
    "\n",
    "### Orthonormal Basis:\n",
    "\n",
    "An orthonormal basis is a special case of an orthogonal basis. In an orthonormal basis, not only are the vectors orthogonal, but they are also normalized (each vector has a length of 1). Mathematically, an orthonormal basis satisfies:\n",
    "\n",
    "$ \\mathbf{v}_i \\cdot \\mathbf{v}_j = 0 \\quad \\text{for } i \\neq j $\n",
    "\n",
    "$ \\|\\mathbf{v}_i\\| = 1 \\quad \\text{for all } i $\n",
    "\n",
    "Now, let's go through examples for both:\n",
    "\n",
    "#### Example of Orthogonal Basis:\n",
    "\n",
    "Consider the vectors $ \\mathbf{v}_1 = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} $ and $ \\mathbf{v}_2 = \\begin{bmatrix} 0 \\\\ -1 \\end{bmatrix} $. These vectors are orthogonal because their dot product is zero:\n",
    "\n",
    "$ \\mathbf{v}_1 \\cdot \\mathbf{v}_2 = (1)(0) + (0)(-1) = 0 $\n",
    "\n",
    "So, the set $ \\{\\mathbf{v}_1, \\mathbf{v}_2\\} $ forms an orthogonal basis.\n",
    "\n",
    "#### Example of Orthonormal Basis:\n",
    "\n",
    "Consider the vectors $ \\mathbf{u}_1 = \\frac{1}{\\sqrt{2}} \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix} $ and $ \\mathbf{u}_2 = \\frac{1}{\\sqrt{2}} \\begin{bmatrix} 1 \\\\ -1 \\end{bmatrix} $. These vectors are not only orthogonal but also normalized:\n",
    "\n",
    "$ \\mathbf{u}_1 \\cdot \\mathbf{u}_2 = \\frac{1}{\\sqrt{2}}\\left(\\frac{1}{\\sqrt{2}}\\right) + \\frac{1}{\\sqrt{2}}\\left(\\frac{-1}{\\sqrt{2}}\\right) = 0 $\n",
    "\n",
    "$ \\|\\mathbf{u}_1\\| = \\|\\mathbf{u}_2\\| = 1 $\n",
    "\n",
    "So, the set $ \\{\\mathbf{u}_1, \\mathbf{u}_2\\} $ forms an orthonormal basis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "007bf17c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5f937e1d",
   "metadata": {},
   "source": [
    "$ \\textbf{14. What is  Orthogonal Complement. Give an example  }$\n",
    "\n",
    "The orthogonal complement of a subspace $ U $ in a vector space $ V $ is a subspace $ U^\\perp $ consisting of all vectors in $ V $ that are orthogonal to every vector in $ U $. Mathematically, the orthogonal complement is denoted as $ U^\\perp $ and defined as:\n",
    "\n",
    "$ U^\\perp = \\{\\mathbf{v} \\in V \\mid \\mathbf{v} \\cdot \\mathbf{u} = 0 \\text{ for all } \\mathbf{u} \\in U\\} $\n",
    "\n",
    "Here, $ \\cdot $ represents the dot product.\n",
    "\n",
    "Let's go through an example:\n",
    "\n",
    "Consider the subspace $ U $ spanned by the vector $ \\mathbf{u} = \\begin{bmatrix} 1 \\\\ 2 \\\\ 1 \\end{bmatrix} $ in $ \\mathbb{R}^3 $. The orthogonal complement $ U^\\perp $ would be the set of all vectors orthogonal to $ \\mathbf{u} $. Let $ \\mathbf{v} = \\begin{bmatrix} x \\\\ y \\\\ z \\end{bmatrix} $. The condition for $ \\mathbf{v} $ to be in $ U^\\perp $ is:\n",
    "\n",
    "$ \\begin{bmatrix} 1 \\\\ 2 \\\\ 1 \\end{bmatrix} \\cdot \\begin{bmatrix} x \\\\ y \\\\ z \\end{bmatrix} = 0 $\n",
    "\n",
    "Solving this, we get the equation $ x + 2y + z = 0 $, which represents a plane in $ \\mathbb{R}^3 $. So, $ U^\\perp $ is the set of all vectors lying in this plane.\n",
    "\n",
    "In general, the orthogonal complement $ U^\\perp $ is a subspace of $ V $ such that $ V = U \\oplus U^\\perp $, where $ \\oplus $ denotes the direct sum. This means that any vector in $ V $ can be uniquely represented as the sum of a vector in $ U $ and a vector in $ U^\\perp $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138bcd6d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3e5bc1d7",
   "metadata": {},
   "source": [
    "$ \\textbf{15. What is Orthogonal Projections . Visualize with sage  }$\n",
    "\n",
    "Sure, here's the given text formatted with `$` for inline math mode:\n",
    "\n",
    "Orthogonal projection is a process in which a vector is projected onto a subspace in a way that the projected vector is orthogonal (perpendicular) to the subspace. In the context of a subspace $U$ in a vector space $V$, the orthogonal projection of a vector $\\mathbf{v}$ onto $U$, denoted as $\\text{proj}_U(\\mathbf{v})$, is the closest vector in $U$ to $\\mathbf{v}$ in terms of distance.\n",
    "\n",
    "Let's visualize this concept using SageMath:\n",
    "\n",
    "```sage\n",
    "# Define the vector and subspace\n",
    "v = vector([3, 2])\n",
    "U = Span([vector([1, 1])])\n",
    "\n",
    "# Compute the orthogonal projection\n",
    "proj_U_v = U.projection(v)\n",
    "\n",
    "# Visualize the vectors and projection\n",
    "p = plot(v, color='blue', legend_label='v', axes_labels=['x', 'y'])\n",
    "p += plot(U.basis()[0], color='green', legend_label='Basis of U')\n",
    "p += plot(proj_U_v, color='red', legend_label='proj_U(v)', linestyle='dashed')\n",
    "p.show()\n",
    "```\n",
    "\n",
    "In this example, we have a vector $\\mathbf{v} = \\langle 3, 2 \\rangle$ and a subspace $U$ spanned by the vector $\\langle 1, 1 \\rangle$. The blue vector represents $\\mathbf{v}$, the green vector represents the basis of $U$, and the red dashed vector represents the orthogonal projection of $\\mathbf{v}$ onto $U$.\n",
    "\n",
    "The orthogonal projection is the vector in $U$ that is closest to $\\mathbf{v}$ in terms of distance. It forms a right angle with the subspace $U$, illustrating the orthogonal property. The orthogonal projection is computed using the `projection` method in SageMath."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc6298ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0fe2cf70",
   "metadata": {},
   "source": [
    "$ \\textbf{16. What is Orthogonal Projections onto 1D subspace. explain and example  }$\n",
    "\n",
    "Orthogonal projections onto a 1D subspace involve projecting a vector onto a line (1D subspace) in a way that the projected vector is orthogonal (perpendicular) to the line. The line can be represented by a vector that spans the subspace.\n",
    "\n",
    "For a 1D subspace \\(U\\) spanned by a vector \\(\\mathbf{u}\\), the orthogonal projection of a vector \\(\\mathbf{v}\\) onto \\(U\\), denoted as \\(\\text{proj}_U(\\mathbf{v})\\), is given by:\n",
    "\n",
    "$  \\text{proj}_U(\\mathbf{v}) = \\frac{\\mathbf{v} \\cdot \\mathbf{u}}{\\|\\mathbf{u}\\|^2} \\cdot \\mathbf{u} $ \n",
    "\n",
    "\n",
    "\n",
    "This formula essentially finds the scalar multiple of $ \\mathbf{u} $ that aligns with the projection of $ \\mathbf{v} $ onto $\\U $.\n",
    "\n",
    "Let's go through an example:\n",
    "\n",
    "Consider the subspace \\(U\\) spanned by the vector $ \\mathbf{u}$ = $ \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$ in $\\mathbb{R}^2 $. Now, let's find the orthogonal projection of the vector $ \\mathbf{v} = \\begin{bmatrix} 3 \\\\ 2 \\end{bmatrix} $ onto $ \\U $.\n",
    "\n",
    "$  \\text{proj}_U(\\mathbf{v}) = \\frac{\\begin{bmatrix} 3 \\\\ 2 \\end{bmatrix} \\cdot \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}}{\\|\\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}\\|^2} \\cdot \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix} $ \n",
    "\n",
    "$  = \\frac{3 + 2}{1^2 + 1^2} \\cdot \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix} $ \n",
    "\n",
    "$  = \\frac{5}{2} \\cdot \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix} $ \n",
    "\n",
    "$  = \\begin{bmatrix} \\frac{5}{2} \\\\ \\frac{5}{2} \\end{bmatrix} $ \n",
    "\n",
    "So, the orthogonal projection of \\(\\mathbf{v}\\) onto the line spanned by $ \\mathbf{u}$ is $\\begin{bmatrix} \\frac{5}{2} \\\\ \\frac{5}{2} \\end{bmatrix}$. This vector is the closest point on the line to $ \\mathbf{v}$ in terms of distance, and it forms a right angle with the line.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38e6b630",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "72aaae3c",
   "metadata": {},
   "source": [
    "$ \\textbf{17. What is Orthogonal Projections onto general subspaces. explain and example  }$\n",
    "\n",
    "Certainly! Here's the provided text formatted using `$` for math mode:\n",
    "\n",
    "Orthogonal projections onto general subspaces extend the concept to subspaces of any dimension. Given a subspace $ \\ U $  in a vector space $ \\ V $ , the orthogonal projection of a vector $ \\ \\mathbf{v} $  onto $ \\ U $ , denoted as $ \\ \\text{proj}_U(\\mathbf{v}) $ , is the closest vector in $ \\ U $  to $ \\ \\mathbf{v} $  in terms of distance, and it is orthogonal to $ \\ U $ .\n",
    "\n",
    "The formula for the orthogonal projection onto a general subspace $ \\ U $  is:\n",
    "\n",
    "$  \\text{proj}_U(\\mathbf{v}) = A(A^TA)^{-1}A^T \\mathbf{v} $ \n",
    "\n",
    "Here:\n",
    "- $ \\ A $  is a matrix whose columns form a basis for the subspace $ \\ U $ .\n",
    "- $ \\ (A^TA)^{-1} $  is the inverse of the matrix product $ \\ A^TA $ .\n",
    "- $ \\ A^T $  is the transpose of the matrix $ \\ A $ .\n",
    "\n",
    "This formula essentially involves transforming the vector $ \\ \\mathbf{v} $  into the subspace $ \\ U $  using the matrix $ \\ A $ , then performing the inverse transformation to find the coordinates of the projection.\n",
    "\n",
    "Let's go through an example:\n",
    "\n",
    "Consider the subspace $ \\ U $  spanned by the vectors $ \\ \\mathbf{u}_1 = \\begin{bmatrix} 1 \\\\ 1 \\\\ 0 \\end{bmatrix} $  and $ \\ \\mathbf{u}_2 = \\begin{bmatrix} 0 \\\\ 1 \\\\ 1 \\end{bmatrix} $  in $ \\ \\mathbb{R}^3 $ . Now, let's find the orthogonal projection of the vector $ \\ \\mathbf{v} = \\begin{bmatrix} 2 \\\\ 3 \\\\ 4 \\end{bmatrix} $  onto $ \\ U $ .\n",
    "\n",
    "Let $ \\ A $  be the matrix whose columns are $ \\ \\mathbf{u}_1 $  and $ \\ \\mathbf{u}_2 $ :\n",
    "\n",
    "$  A = \\begin{bmatrix} 1 & 0 \\\\ 1 & 1 \\\\ 0 & 1 \\end{bmatrix} $ \n",
    "\n",
    "Now, calculate the orthogonal projection:\n",
    "\n",
    "$  \\text{proj}_U(\\mathbf{v}) = A(A^TA)^{-1}A^T \\mathbf{v} $ \n",
    "\n",
    "This involves matrix multiplication and inversion, and the result will be the closest vector in $ \\ U $  to $ \\ \\mathbf{v} $  in terms of distance. The formula generalizes the concept of orthogonal projections to subspaces of any dimension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f7f800",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "08474dbe",
   "metadata": {},
   "source": [
    "$ \\textbf{18. Gram-Schmidt Orthogonalization. Explain and give examples  }$\n",
    "\n",
    "Sure thing! Here's your text with the LaTeX expressions converted to inline math mode using `$`:\n",
    "\n",
    "Gram-Schmidt orthogonalization is a process used to transform a linearly independent set of vectors into an orthogonal (or orthonormal) set. This method is particularly useful when dealing with bases or spanning sets of vectors.\n",
    "\n",
    "Given a set of linearly independent vectors $ \\mathbf{v}_1, \\mathbf{v}_2, \\ldots, \\mathbf{v}_n $, the Gram-Schmidt process produces an orthogonal (or orthonormal) set $ \\mathbf{u}_1, \\mathbf{u}_2, \\ldots, \\mathbf{u}_n $ that spans the same subspace as the original vectors.\n",
    "\n",
    "The process is as follows:\n",
    "\n",
    "1. **Initialization:**\n",
    "   $ \\mathbf{u}_1 = \\mathbf{v}_1 $\n",
    "\n",
    "2. **Orthogonalization:**\n",
    "   $ \\mathbf{u}_k = \\mathbf{v}_k - \\text{proj}_{\\mathbf{u}_1}(\\mathbf{v}_k) - \\text{proj}_{\\mathbf{u}_2}(\\mathbf{v}_k) - \\ldots - \\text{proj}_{\\mathbf{u}_{k-1}}(\\mathbf{v}_k) $\n",
    "   where $ \\text{proj}_{\\mathbf{u}_i}(\\mathbf{v}_k) $ is the orthogonal projection of $ \\mathbf{v}_k $ onto $ \\mathbf{u}_i $.\n",
    "\n",
    "3. **Normalization (for orthonormalization):**\n",
    "   $ \\mathbf{e}_k = \\frac{\\mathbf{u}_k}{\\|\\mathbf{u}_k\\|} $\n",
    "\n",
    "Now, let's go through an example:\n",
    "\n",
    "Consider the vectors $ \\mathbf{v}_1 = \\begin{bmatrix} 1 \\\\ 1 \\\\ 0 \\end{bmatrix} $, $ \\mathbf{v}_2 = \\begin{bmatrix} 1 \\\\ 0 \\\\ 1 \\end{bmatrix} $, and $ \\mathbf{v}_3 = \\begin{bmatrix} 0 \\\\ 1 \\\\ 1 \\end{bmatrix} $.\n",
    "\n",
    "1. **Initialization:**\n",
    "   $ \\mathbf{u}_1 = \\mathbf{v}_1 = \\begin{bmatrix} 1 \\\\ 1 \\\\ 0 \\end{bmatrix} $\n",
    "\n",
    "2. **Orthogonalization:**\n",
    "   $ \\mathbf{u}_2 = \\mathbf{v}_2 - \\text{proj}_{\\mathbf{u}_1}(\\mathbf{v}_2) $\n",
    "   $ \\mathbf{u}_3 = \\mathbf{v}_3 - \\text{proj}_{\\mathbf{u}_1}(\\mathbf{v}_3) - \\text{proj}_{\\mathbf{u}_2}(\\mathbf{v}_3) $\n",
    "\n",
    "3. **Normalization:**\n",
    "   Normalize $ \\mathbf{u}_2 $ and $ \\mathbf{u}_3 $ if orthonormalization is desired.\n",
    "\n",
    "The resulting vectors $ \\mathbf{u}_1, \\mathbf{u}_2, \\mathbf{u}_3 $ will be orthogonal (or orthonormal) and span the same subspace as the original vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fed05ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3f0eb5df",
   "metadata": {},
   "source": [
    "$ \\textbf{19. Explain Rotations in R^3 . What are the properties? Give examples  }$\n",
    "\n",
    "Rotations in $\\mathbb{R}^3$ involve transforming points or vectors in three-dimensional space around an axis. Unlike rotations in $\\mathbb{R}^2$, which occur in a plane, rotations in $\\mathbb{R}^3$ occur about an axis, and the axis of rotation is defined by a line.\n",
    "\n",
    "Properties of Rotations in $\\mathbb{R}^3$:\n",
    "\n",
    "1. **Axis of Rotation:** A rotation in $\\mathbb{R}^3$ is defined by an axis, which is a line passing through the origin.\n",
    "\n",
    "2. **Angle of Rotation:** The angle of rotation specifies the amount by which the points or vectors are rotated about the axis.\n",
    "\n",
    "3. **Preservation of Distance:** Rotations in $\\mathbb{R}^3$ preserve distances between points. If $\\mathbf{P}$ and $\\mathbf{Q}$ are two points before rotation, their distance $\\|\\mathbf{P} - \\mathbf{Q}\\|$ will be the same after rotation.\n",
    "\n",
    "4. **Orthogonality:** Rotations preserve angles between vectors. If $\\mathbf{V}$ and $\\mathbf{W}$ are two vectors before rotation, the angle between them will remain the same after rotation.\n",
    "\n",
    "5. **Rotation Matrix:** A rotation in $\\mathbb{R}^3$ can be represented by a 3x3 rotation matrix. The form of the matrix depends on the axis of rotation and the angle of rotation.\n",
    "\n",
    "Here's an example of a rotation in $\\mathbb{R}^3$:\n",
    "\n",
    "Let's consider a rotation of $90^\\circ$ about the z-axis. The rotation matrix for this is:\n",
    "\n",
    "$  R_z(90^\\circ) = \\begin{bmatrix} \\cos(90^\\circ) & -\\sin(90^\\circ) & 0 \\\\ \\sin(90^\\circ) & \\cos(90^\\circ) & 0 \\\\ 0 & 0 & 1 \\end{bmatrix} = \\begin{bmatrix} 0 & -1 & 0 \\\\ 1 & 0 & 0 \\\\ 0 & 0 & 1 \\end{bmatrix} $ \n",
    "\n",
    "If you have a vector $\\mathbf{v} = \\begin{bmatrix} 1 \\\\ 0 \\\\ 0 \\end{bmatrix}$, a rotation of $90^\\circ$ about the z-axis will result in the vector $\\mathbf{R}_z(90^\\circ) \\cdot \\mathbf{v} = \\begin{bmatrix} 0 \\\\ 1 \\\\ 0 \\end{bmatrix}$. This means that the original x-axis is rotated into the y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46e2fcf1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "181b2d60",
   "metadata": {},
   "source": [
    "$ \\textbf{20. Explain Rotations in R^2 . What are the properties? Give examples  }$\n",
    "\n",
    "Sure thing! Here's your text with inline math expressions enclosed in dollar signs:\n",
    "\n",
    "Rotations in $ \\mathbb{R}^2 $ involve transforming points or vectors in two-dimensional space around the origin. A rotation in $ \\mathbb{R}^2 $ is often described by an angle of rotation and can be represented by a rotation matrix.\n",
    "\n",
    "**Properties of Rotations in $ \\mathbb{R}^2 $:**\n",
    "\n",
    "1. **Angle of Rotation:** A rotation in $ \\mathbb{R}^2 $ is defined by an angle of rotation $ \\theta $, which specifies the amount by which points or vectors are rotated counterclockwise about the origin.\n",
    "\n",
    "2. **Rotation Matrix:** The rotation matrix for a rotation in $ \\mathbb{R}^2 $ is given by:\n",
    "\n",
    "   $  R(\\theta) = \\begin{bmatrix} \\cos(\\theta) & -\\sin(\\theta) \\\\ \\sin(\\theta) & \\cos(\\theta) \\end{bmatrix} $ \n",
    "\n",
    "   This matrix rotates a vector $ \\mathbf{v} = \\begin{bmatrix} x \\\\ y \\end{bmatrix} $ counterclockwise by an angle $ \\theta $ to obtain $ \\mathbf{R}(\\theta) \\cdot \\mathbf{v} $.\n",
    "\n",
    "3. **Preservation of Distance:** Rotations in $ \\mathbb{R}^2 $ preserve distances between points. If $ \\mathbf{P} $ and $ \\mathbf{Q} $ are two points before rotation, their distance $ \\|\\mathbf{P} - \\mathbf{Q}\\| $ will be the same after rotation.\n",
    "\n",
    "4. **Orthogonality:** Rotations preserve angles between vectors. If $ \\mathbf{V} $ and $ \\mathbf{W} $ are two vectors before rotation, the angle between them will remain the same after rotation.\n",
    "\n",
    "**Example of a Rotation in $ \\mathbb{R}^2 $:**\n",
    "\n",
    "Let's consider a rotation of $ 45^\\circ $ counterclockwise. The rotation matrix for this rotation is:\n",
    "\n",
    "$  R(45^\\circ) = \\begin{bmatrix} \\cos(45^\\circ) & -\\sin(45^\\circ) \\\\ \\sin(45^\\circ) & \\cos(45^\\circ) \\end{bmatrix} = \\frac{1}{\\sqrt{2}} \\begin{bmatrix} 1 & -1 \\\\ 1 & 1 \\end{bmatrix} $ \n",
    "\n",
    "If you have a vector $ \\mathbf{v} = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} $, a rotation of $ 45^\\circ $ counterclockwise will result in the vector $ \\mathbf{R}(45^\\circ) \\cdot \\mathbf{v} = \\frac{1}{\\sqrt{2}} \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix} $. This means that the original x-axis is rotated into the line $ y = x $."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4f9ab8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b26b2f55",
   "metadata": {},
   "source": [
    "$ \\textbf{21. What are the Rotation Matrices in R^3?   }$\n",
    "\n",
    "Certainly! Here's the text with inline math expressions enclosed in dollar signs:\n",
    "\n",
    "Rotation matrices in $ \\mathbb{R}^3 $ are 3x3 matrices that represent rotations in three-dimensional space. Similar to rotations in $ \\mathbb{R}^2 $, these matrices are designed to perform rotations about specific axes.\n",
    "\n",
    "Here are the rotation matrices for rotations about the coordinate axes:\n",
    "\n",
    "1. **Rotation about the x-axis (Roll):**\n",
    "   $ R_x(\\theta) = \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & \\cos(\\theta) & -\\sin(\\theta) \\\\ 0 & \\sin(\\theta) & \\cos(\\theta) \\end{bmatrix} $\n",
    "\n",
    "2. **Rotation about the y-axis (Pitch):**\n",
    "   $ R_y(\\theta) = \\begin{bmatrix} \\cos(\\theta) & 0 & \\sin(\\theta) \\\\ 0 & 1 & 0 \\\\ -\\sin(\\theta) & 0 & \\cos(\\theta) \\end{bmatrix} $\n",
    "\n",
    "3. **Rotation about the z-axis (Yaw):**\n",
    "   $ R_z(\\theta) = \\begin{bmatrix} \\cos(\\theta) & -\\sin(\\theta) & 0 \\\\ \\sin(\\theta) & \\cos(\\theta) & 0 \\\\ 0 & 0 & 1 \\end{bmatrix} $\n",
    "\n",
    "Here, $ \\theta $ represents the angle of rotation. To perform a rotation, multiply the rotation matrix by the column vector representing the point or vector to be rotated.\n",
    "\n",
    "For example, if $ \\mathbf{v} = \\begin{bmatrix} x \\\\ y \\\\ z \\end{bmatrix} $ is a vector in $ \\mathbb{R}^3 $, then the rotated vector $ \\mathbf{R}_x(\\theta) \\cdot \\mathbf{v} $ represents the result of rotating $ \\mathbf{v} $ about the x-axis by an angle $ \\theta $. Similarly, $ \\mathbf{R}_y(\\theta) \\cdot \\mathbf{v} $ and $ \\mathbf{R}_z(\\theta) \\cdot \\mathbf{v} $ represent rotations about the y-axis and z-axis, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be30b1f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d9263f75",
   "metadata": {},
   "source": [
    "$ \\textbf{22. Give R^3 Rotation examples for 30, 45, 60, 90 degrees  }$\n",
    "\n",
    "Certainly! Let's provide examples of rotation matrices for rotations about the x, y, and z axes in $  \\mathbb{R}^3 $  for angles of 30, 45, 60, and 90 degrees.\n",
    "\n",
    "1. **Rotation about the x-axis:**\n",
    "   - $  R_x(30^\\circ) = \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & \\cos(30^\\circ) & -\\sin(30^\\circ) \\\\ 0 & \\sin(30^\\circ) & \\cos(30^\\circ) \\end{bmatrix} $ \n",
    "\n",
    "   - $  R_x(45^\\circ) = \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & \\cos(45^\\circ) & -\\sin(45^\\circ) \\\\ 0 & \\sin(45^\\circ) & \\cos(45^\\circ) \\end{bmatrix} $ \n",
    "\n",
    "   - $  R_x(60^\\circ) = \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & \\cos(60^\\circ) & -\\sin(60^\\circ) \\\\ 0 & \\sin(60^\\circ) & \\cos(60^\\circ) \\end{bmatrix} $ \n",
    "\n",
    "   - $  R_x(90^\\circ) = \\begin{bmatrix} 1 & 0 & 0 \\\\ 0 & \\cos(90^\\circ) & -\\sin(90^\\circ) \\\\ 0 & \\sin(90^\\circ) & \\cos(90^\\circ) \\end{bmatrix} $ \n",
    "\n",
    "2. **Rotation about the y-axis:**\n",
    "   - $  R_y(30^\\circ) = \\begin{bmatrix} \\cos(30^\\circ) & 0 & \\sin(30^\\circ) \\\\ 0 & 1 & 0 \\\\ -\\sin(30^\\circ) & 0 & \\cos(30^\\circ) \\end{bmatrix} $ \n",
    "\n",
    "   - $  R_y(45^\\circ) = \\begin{bmatrix} \\cos(45^\\circ) & 0 & \\sin(45^\\circ) \\\\ 0 & 1 & 0 \\\\ -\\sin(45^\\circ) & 0 & \\cos(45^\\circ) \\end{bmatrix} $ \n",
    "\n",
    "   - $  R_y(60^\\circ) = \\begin{bmatrix} \\cos(60^\\circ) & 0 & \\sin(60^\\circ) \\\\ 0 & 1 & 0 \\\\ -\\sin(60^\\circ) & 0 & \\cos(60^\\circ) \\end{bmatrix} $ \n",
    "\n",
    "   - $  R_y(90^\\circ) = \\begin{bmatrix} \\cos(90^\\circ) & 0 & \\sin(90^\\circ) \\\\ 0 & 1 & 0 \\\\ -\\sin(90^\\circ) & 0 & \\cos(90^\\circ) \\end{bmatrix} $ \n",
    "\n",
    "3. **Rotation about the z-axis:**\n",
    "   - $  R_z(30^\\circ) = \\begin{bmatrix} \\cos(30^\\circ) & -\\sin(30^\\circ) & 0 \\\\ \\sin(30^\\circ) & \\cos(30^\\circ) & 0 \\\\ 0 & 0 & 1 \\end{bmatrix} $ \n",
    "\n",
    "   - $  R_z(45^\\circ) = \\begin{bmatrix} \\cos(45^\\circ) & -\\sin(45^\\circ) & 0 \\\\ \\sin(45^\\circ) & \\cos(45^\\circ) & 0 \\\\ 0 & 0 & 1 \\end{bmatrix} $ \n",
    "\n",
    "   - $  R_z(60^\\circ) = \\begin{bmatrix} \\cos(60^\\circ) & -\\sin(60^\\circ) & 0 \\\\ \\sin(60^\\circ) & \\cos(60^\\circ) & 0 \\\\ 0 & 0 & 1 \\end{bmatrix} $ \n",
    "\n",
    "   - $  R_z(90^\\circ) = \\begin{bmatrix} \\cos(90^\\circ) & -\\sin(90^\\circ) & 0 \\\\ \\sin(90^\\circ) & \\cos(90^\\circ) & 0 \\\\ 0 & 0 & 1 \\end{bmatrix} $ \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7028daa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SageMath 9.5",
   "language": "sage",
   "name": "sagemath"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
